# 1 - Search
# Options: searxng, tavily, serper, bing
SEARCH_PROVIDER=searxng
SEARXNG_BASE_URL=http://searxng:8080

# tavily, serper, bing (Optional)
TAVILY_API_KEY=
SERPER_API_KEY=
BING_API_KEY=

# 2 - LLM Providers

# Options: openai, azure, gpt4all, llama2, gpt4all-j, gpt4all-j-gguf, gpt4all-j-gguf-quantized

# grok
GROQ_API_KEY=

# OLLAMA
OLLAMA_API_BASE=http://64.227.148.221:11434

# Cloud Models (Optional)
OPENAI_API_KEY=
OPENAI_API_BASE=

# azure
AZURE_DEPLOYMENT_NAME=
AZURE_API_KEY=
AZURE_API_BASE=
AZURE_API_VERSION=

# azure, openai
OPENAI_MODE=azure

# Any `provider/model` from https://litellm.vercel.app/docs/providers
CUSTOM_MODEL=

# 3 - Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000

# Database URL
DATABASE_URL=
DB_ENABLED=True


# 4 - Caching + Rate Limiting (Optional)
RATE_LIMIT_ENABLED=False
REDIS_URL=

# 5 - Local Models
ENABLE_LOCAL_MODELS=True
NEXT_PUBLIC_LOCAL_MODE_ENABLED=True
NEXT_PUBLIC_PRO_MODE_ENABLED=True

# 6 - Pro Mode (Optional)
STRIPE_SECRET_KEY=
STRIPE_WEBHOOK_SECRET=
STRIPE_PUBLISHABLE_KEY=
STRIPE_PRICE_ID=
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=